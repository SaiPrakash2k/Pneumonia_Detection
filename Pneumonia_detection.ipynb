{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers,models\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data=pd.read_csv('Chest_xray_Corona_Metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_data.columnsContains 165 grayscale images in GIF format of 15 individuals. There are 11 images per subject, one per different facial expression or configuration: center-light, w/glasses, happy, left-light, w/no glasses, normal, right-light, sad, sleepy, surprised, and wink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data=meta_data.drop(['Unnamed: 0'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_ray_image_name</th>\n",
       "      <th>Label</th>\n",
       "      <th>Dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IM-0128-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IM-0127-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IM-0125-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IM-0122-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IM-0119-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IM-0117-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IM-0115-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IM-0189-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IM-0187-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IM-0185-0001.jpeg</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X_ray_image_name   Label Dataset_type\n",
       "0  IM-0128-0001.jpeg  Normal        TRAIN\n",
       "1  IM-0127-0001.jpeg  Normal        TRAIN\n",
       "2  IM-0125-0001.jpeg  Normal        TRAIN\n",
       "3  IM-0122-0001.jpeg  Normal        TRAIN\n",
       "4  IM-0119-0001.jpeg  Normal        TRAIN\n",
       "5  IM-0117-0001.jpeg  Normal        TRAIN\n",
       "6  IM-0115-0001.jpeg  Normal        TRAIN\n",
       "7  IM-0189-0001.jpeg  Normal        TRAIN\n",
       "8  IM-0187-0001.jpeg  Normal        TRAIN\n",
       "9  IM-0185-0001.jpeg  Normal        TRAIN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = meta_data.drop(['Label_2_Virus_category','Label_1_Virus_category'],axis=1)\n",
    "meta_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5286\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "train=[]\n",
    "test=[]\n",
    "for i in range(len(meta_data)):\n",
    "    if meta_data.iloc[i][2]=='TRAIN':\n",
    "        train.append(meta_data.iloc[i][0])\n",
    "    else :\n",
    "        test.append(meta_data.iloc[i][0])\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                X_ray_image_name Label Dataset_type\n",
      "5900  person1644_virus_2844.jpeg     1         TEST\n",
      "5901  person1643_virus_2843.jpeg     1         TEST\n",
      "5902  person1642_virus_2842.jpeg     1         TEST\n",
      "5903  person1641_virus_2840.jpeg     1         TEST\n",
      "5904  person1640_virus_2839.jpeg     1         TEST\n",
      "5905  person1637_virus_2834.jpeg     1         TEST\n",
      "5906  person1635_virus_2831.jpeg     1         TEST\n",
      "5907  person1634_virus_2830.jpeg     1         TEST\n",
      "5908  person1633_virus_2829.jpeg     1         TEST\n",
      "5909  person1632_virus_2827.jpeg     1         TEST\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(meta_data)):\n",
    "    if meta_data.iloc[i]['Label']=='Normal':\n",
    "        meta_data.iloc[i]['Label'] = 0\n",
    "    else:\n",
    "        meta_data.iloc[i]['Label'] = 1\n",
    "        \n",
    "print(meta_data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = meta_data[meta_data['Dataset_type']=='TRAIN']\n",
    "test_data = meta_data[meta_data['Dataset_type']=='TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(img_dims, batch_size):\n",
    "    # Data generation objects\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, vertical_flip=True)\n",
    "    test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "    directory='train', \n",
    "    target_size=(img_dims, img_dims), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary', \n",
    "    shuffle=True)\n",
    "    \n",
    "    test_gen = test_val_datagen.flow_from_directory(\n",
    "    directory='test', \n",
    "    target_size=(img_dims, img_dims), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary', \n",
    "    shuffle=True)\n",
    "    \n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "\n",
    "    for cond in ['/NORMAL/', '/PNEUMONIA/']:\n",
    "        for img in (os.listdir('test' + cond)):\n",
    "            img = plt.imread('test'+cond+img)\n",
    "            img = cv2.resize(img, (img_dims, img_dims))\n",
    "            img = np.dstack([img, img, img])\n",
    "            img = img.astype('float32') / 255\n",
    "            if cond=='/NORMAL/':\n",
    "                label = 0\n",
    "            elif cond=='/PNEUMONIA/':\n",
    "                label = 1\n",
    "            test_data.append(img)\n",
    "            test_labels.append(label)\n",
    "        \n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_gen, test_gen, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_dims = 150\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "train_gen,test_gen,test_data,test_labels = process_data(img_dims,batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(img_dims, img_dims, 3))\n",
    "\n",
    "# First conv block\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Second conv block\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Third conv block\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Fourth conv block\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "\n",
    "# Fifth conv block\n",
    "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "\n",
    "# FC layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(rate=0.7)(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(units=64, activation='relu')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "# Creating model and compiling\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs=pd.Series(trainimg)\n",
    "test_imgs=pd.Series(testimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/81 [==============================] - 60s 746ms/step - loss: 0.3751 - accuracy: 0.8158 - val_loss: 0.8033 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 58s 716ms/step - loss: 0.2816 - accuracy: 0.8783 - val_loss: 0.9253 - val_accuracy: 0.6302 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 58s 720ms/step - loss: 0.2493 - accuracy: 0.8991 - val_loss: 0.7356 - val_accuracy: 0.6198 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.9074\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "81/81 [==============================] - 57s 703ms/step - loss: 0.2290 - accuracy: 0.9074 - val_loss: 0.9246 - val_accuracy: 0.6181 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 57s 707ms/step - loss: 0.1806 - accuracy: 0.9328 - val_loss: 1.0648 - val_accuracy: 0.6302 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 59s 725ms/step - loss: 0.1688 - accuracy: 0.9356 - val_loss: 1.4809 - val_accuracy: 0.6285 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 56s 696ms/step - loss: 0.1638 - accuracy: 0.9400 - val_loss: 2.0386 - val_accuracy: 0.6146 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 56s 690ms/step - loss: 0.1440 - accuracy: 0.9468 - val_loss: 1.8447 - val_accuracy: 0.6233 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9505\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "81/81 [==============================] - 57s 704ms/step - loss: 0.1357 - accuracy: 0.9505 - val_loss: 1.6958 - val_accuracy: 0.6215 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 56s 695ms/step - loss: 0.1240 - accuracy: 0.9563 - val_loss: 0.6838 - val_accuracy: 0.7205 - lr: 9.0000e-05\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9567\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "81/81 [==============================] - 55s 676ms/step - loss: 0.1258 - accuracy: 0.9567 - val_loss: 0.2564 - val_accuracy: 0.9045 - lr: 9.0000e-05\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 55s 682ms/step - loss: 0.1234 - accuracy: 0.9565 - val_loss: 0.3180 - val_accuracy: 0.8819 - lr: 2.7000e-05\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.9557\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "81/81 [==============================] - 55s 677ms/step - loss: 0.1227 - accuracy: 0.9557 - val_loss: 0.2613 - val_accuracy: 0.8941 - lr: 2.7000e-05\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 56s 692ms/step - loss: 0.1190 - accuracy: 0.9590 - val_loss: 0.2426 - val_accuracy: 0.9097 - lr: 8.1000e-06\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9590\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "81/81 [==============================] - 55s 681ms/step - loss: 0.1180 - accuracy: 0.9590 - val_loss: 0.2362 - val_accuracy: 0.9167 - lr: 8.1000e-06\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 55s 684ms/step - loss: 0.1259 - accuracy: 0.9567 - val_loss: 0.2681 - val_accuracy: 0.8941 - lr: 2.4300e-06\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9585\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "81/81 [==============================] - 57s 706ms/step - loss: 0.1235 - accuracy: 0.9585 - val_loss: 0.2739 - val_accuracy: 0.8924 - lr: 2.4300e-06\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 57s 706ms/step - loss: 0.1168 - accuracy: 0.9585 - val_loss: 0.2669 - val_accuracy: 0.8993 - lr: 7.2900e-07\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9610\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
      "81/81 [==============================] - 57s 704ms/step - loss: 0.1122 - accuracy: 0.9610 - val_loss: 0.2469 - val_accuracy: 0.9045 - lr: 7.2900e-07\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 57s 706ms/step - loss: 0.1234 - accuracy: 0.9565 - val_loss: 0.2682 - val_accuracy: 0.8993 - lr: 2.1870e-07\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "           train_gen, steps_per_epoch=train_gen.samples // batch_size, \n",
    "           epochs=epochs, validation_data=test_gen, \n",
    "           validation_steps=test_gen.samples // batch_size, callbacks=[checkpoint, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Pneumonia_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "preds = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8942307692307693\n",
      "[[182  52]\n",
      " [ 14 376]]\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(test_labels,np.round(preds))\n",
    "conf_mat = confusion_matrix(test_labels, np.round(preds))\n",
    "tn,fp,fn,tp =  conf_mat.ravel()\n",
    "\n",
    "print(acc_score)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
